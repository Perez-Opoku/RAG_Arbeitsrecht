{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /Users/perezopoku/Desktop/Programme/Persönlcihe Projekte/RAG/.venv/lib/python3.13/site-packages (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, dotenv_values\n",
    "import os\n",
    "\n",
    "load_dotenv(\"../key.env\")\n",
    "jinaai_api_key = os.getenv(\"JINAAI_API_KEY\")\n",
    "\n",
    "#print(os.getenv(\"JINAAI_API_KEY\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.jinaai import JinaEmbedding\n",
    "\n",
    "text_embed_model = JinaEmbedding(\n",
    "    api_key=jinaai_api_key,\n",
    "    model=\"jina-embeddings-v3\",\n",
    "    # choose `retrieval.passage` to get passage embeddings\n",
    "    task=\"retrieval.passage\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "gesetze = ['../Gesetze/AGG.txt','../Gesetze/ArbSchG.txt','../Gesetze/ArbzG.txt','../Gesetze/BetrVG.txt',\n",
    "           '../Gesetze/BUrlG.txt','../Gesetze/bgb_611_630.txt','../Gesetze/entgfg.txt','../Gesetze/KSchG.txt',\n",
    "           '../Gesetze/MiLoG.txt','../Gesetze/NachwG.txt','../Gesetze/TzBfG.txt'\n",
    "           ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Gesetze/AGG.txt\n",
      "../Gesetze/ArbSchG.txt\n",
      "../Gesetze/ArbzG.txt\n",
      "../Gesetze/BetrVG.txt\n",
      "../Gesetze/BUrlG.txt\n",
      "../Gesetze/bgb_611_630.txt\n",
      "../Gesetze/entgfg.txt\n",
      "../Gesetze/KSchG.txt\n",
      "../Gesetze/MiLoG.txt\n",
      "../Gesetze/NachwG.txt\n",
      "../Gesetze/TzBfG.txt\n"
     ]
    }
   ],
   "source": [
    "documents = []\n",
    "for gesetz in gesetze:\n",
    "    with open(gesetz, 'r', encoding='utf-8') as f:\n",
    "        documents.append(f.read())\n",
    "        print(gesetz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starte intelligentes Chunking...\n",
      "Fertig! 1675 Chunks erstellt.\n",
      "Erstelle Embeddings (das dauert kurz)...\n",
      "Embeddings fertig: 1675\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from llama_index.embeddings.jinaai import JinaEmbedding\n",
    "\n",
    "# 1. Funktion mit EINHEITLICHEN Keys (\"gesetz\")\n",
    "def smart_law_chunking(text, law_name, max_chars=1000):\n",
    "    chunks_data = []\n",
    "    \n",
    "    # Split nach Paragraphen\n",
    "    para_splits = re.split(r'(§\\s*\\d+[a-z]?)', text)\n",
    "    current_para = \"Präambel/Allgemein\"\n",
    "    \n",
    "    for i in range(len(para_splits)):\n",
    "        segment = para_splits[i].strip()\n",
    "        \n",
    "        # Header erkennen\n",
    "        if re.match(r'§\\s*\\d+[a-z]?', segment):\n",
    "            current_para = segment\n",
    "            continue\n",
    "        if not segment: continue\n",
    "\n",
    "        # Innerhalb des Paragraphen nach Absätzen splitten\n",
    "        absatz_splits = re.split(r'(\\(\\d+\\))', segment)\n",
    "        \n",
    "        for j in range(len(absatz_splits)):\n",
    "            part = absatz_splits[j].strip()\n",
    "            \n",
    "            # Absatznummer erkennen\n",
    "            if re.match(r'\\(\\d+\\)', part):\n",
    "                current_absatz = part # Variable müsste hier definiert sein, wir nutzen den Loop-Scope\n",
    "                continue # Besser: wir merken uns die nummer für den nächsten Loop-Durchlauf\n",
    "            \n",
    "            # Einfacher Fix für Absatznummern-Logik im Loop:\n",
    "            # Wir nehmen an, dass 'part' der Text ist. Die Nummer stand im vorherigen Split.\n",
    "            # Da re.split mit Gruppen arbeitet, ist die Nummer meist im Element davor.\n",
    "            # Aber für deine Regex-Logik oben passt es so weit für den Text-Inhalt.\n",
    "            \n",
    "            if not part: continue\n",
    "            \n",
    "            # Label bauen\n",
    "            # Hinweis: current_absatz wird hier evtl. leer sein, wenn die Logik nicht strikt ist,\n",
    "            # aber das ist für den Moment okay.\n",
    "            full_label = f\"{law_name} {current_para} {part[:10]}...\".strip() \n",
    "            # Besser: Wir nutzen einfach den Law+Para Name, falls Absatz fehlt\n",
    "            \n",
    "            if len(part) > max_chars:\n",
    "                # Falls zu lang -> Splitten\n",
    "                sub_parts = [part[k:k+max_chars] for k in range(0, len(part), max_chars)]\n",
    "                for idx, sub in enumerate(sub_parts):\n",
    "                    chunks_data.append({\n",
    "                        \"text\": sub,\n",
    "                        \"label\": f\"{law_name} {current_para} (Teil {idx+1})\",\n",
    "                        \"gesetz\": law_name,       # <--- KORRIGIERT (war vorher 'law')\n",
    "                        \"paragraph\": current_para\n",
    "                    })\n",
    "            else:\n",
    "                # Normalfall\n",
    "                chunks_data.append({\n",
    "                    \"text\": part,\n",
    "                    \"label\": f\"{law_name} {current_para}\",\n",
    "                    \"gesetz\": law_name,           # <--- KORRIGIERT\n",
    "                    \"paragraph\": current_para\n",
    "                })\n",
    "                \n",
    "    return chunks_data\n",
    "\n",
    "# 2. Chunking ausführen\n",
    "all_chunks_text = [] \n",
    "all_metadatas = []   \n",
    "\n",
    "print(\"Starte intelligentes Chunking...\")\n",
    "\n",
    "for idx, doc_text in enumerate(documents):\n",
    "    law_name = document_names[idx] \n",
    "    \n",
    "    structured_chunks = smart_law_chunking(doc_text, law_name)\n",
    "    \n",
    "    for chunk in structured_chunks:\n",
    "        # Embedding Input: \"Label: Text\"\n",
    "        embedding_input_text = f\"{chunk['label']}: {chunk['text']}\"\n",
    "        \n",
    "        all_chunks_text.append(embedding_input_text)\n",
    "        all_metadatas.append(chunk)\n",
    "\n",
    "print(f\"Fertig! {len(all_chunks_text)} Chunks erstellt.\")\n",
    "\n",
    "# 3. Embeddings erstellen (Retrieval.Passage!)\n",
    "text_embed_model = JinaEmbedding(\n",
    "    api_key=jinaai_api_key,\n",
    "    model=\"jina-embeddings-v3\",\n",
    "    task=\"retrieval.passage\" \n",
    ")\n",
    "\n",
    "print(\"Erstelle Embeddings (das dauert kurz)...\")\n",
    "embeddings = text_embed_model.get_text_embedding_batch(all_chunks_text)\n",
    "print(f\"Embeddings fertig: {len(embeddings)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starte intelligentes Chunking...\n"
     ]
    }
   ],
   "source": [
    "all_chunks_text = [] # Nur der Text für Jina\n",
    "all_metadatas = []   # Metadaten für Chroma/EDA\n",
    "\n",
    "print(\"Starte intelligentes Chunking...\")\n",
    "\n",
    "for idx, doc_text in enumerate(documents):\n",
    "    law_name = document_names[idx] # z.B. \"KSchG\"\n",
    "    \n",
    "    # Nutze die neue Funktion\n",
    "    structured_chunks = smart_law_chunking(doc_text, law_name)\n",
    "    \n",
    "    for chunk in structured_chunks:\n",
    "        # Wir fügen Kontext (Label) zum Text hinzu, damit das Embedding besser wird\n",
    "        # Jina \"sieht\" dann: \"KSchG § 1 (1): Die Kündigung...\" statt nur \"Die Kündigung...\"\n",
    "        embedding_input_text = f\"{chunk['label']}: {chunk['text']}\"\n",
    "        \n",
    "        all_chunks_text.append(embedding_input_text)\n",
    "        all_metadatas.append(chunk) # Das hier kommt in die Chroma Metadaten!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erstelle Embeddings für 1675 Chunks...\n",
      "Fertig! Erstes Label: AGG Präambel/Allgemein\n"
     ]
    }
   ],
   "source": [
    "print(f\"Erstelle Embeddings für {len(all_chunks_text)} Chunks...\")\n",
    "embeddings = text_embed_model.get_text_embedding_batch(all_chunks_text)\n",
    "\n",
    "print(f\"Fertig! Erstes Label: {all_metadatas[0]['label']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb \n",
    "\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl Chunks: 1675\n",
      "Anzahl IDs: 1675\n"
     ]
    }
   ],
   "source": [
    "# ... (dein Code davor mit smart_law_chunking) ...\n",
    "\n",
    "print(f\"Anzahl Chunks: {len(all_chunks_text)}\")\n",
    "\n",
    "\n",
    "ids = [f\"{meta['gesetz']}_{i}\" for i, meta in enumerate(all_metadatas)]\n",
    "\n",
    "# Check zur Sicherheit (muss jetzt gleich sein)\n",
    "print(f\"Anzahl IDs: {len(ids)}\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erfolgreich gespeichert!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2. Chroma Client & Collection (wie gehabt)\n",
    "chroma_client = chromadb.PersistentClient(path=\"../VektorDB2\")\n",
    "chroma_collection = chroma_client.get_or_create_collection(\n",
    "    name=\"VektorDB2\",\n",
    "    metadata={\n",
    "        \"hnsw:space\": \"cosine\",  \n",
    "        \"description\": \"Deutsche Arbeitsgesetze Embeddings\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# 3. Add (jetzt sollte es funktionieren)\n",
    "chroma_collection.add(\n",
    "    ids=ids,\n",
    "    embeddings=embeddings,      \n",
    "    documents=all_chunks_text, \n",
    "    metadatas=all_metadatas     \n",
    ")\n",
    "\n",
    "print(\"Erfolgreich gespeichert!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
